{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install portalocker"
      ],
      "metadata": {
        "id": "XytWiVRZ-NhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "!pip install -U torchdata\n",
        "!pip install -U spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download de_core_news_sm\n",
        "!pip install torchtext==0.15.1\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "SQS2_BjE8WM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "SEED = 1234\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "url = \"https://www.gutenberg.org/files/4300/4300-0.txt\"\n",
        "response = requests.get(url)\n",
        "if response.status_code == 200:\n",
        "    full_text = response.text\n",
        "else:\n",
        "    full_text = \"Download failed.\"\n",
        "\n",
        "words = full_text.split()\n",
        "num_pages = 25\n",
        "words_per_page = 1000\n",
        "subset_words = words[:num_pages * words_per_page]\n",
        "ulysses_subset = \" \".join(subset_words)\n",
        "text = ulysses_subset\n",
        "\n",
        "tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "tokenized_text = tokenizer(text)\n",
        "window_size = 4\n",
        "inputs = []\n",
        "targets = []\n",
        "for i in range(len(tokenized_text) - window_size):\n",
        "    inputs.append(tokenized_text[i:i+window_size])\n",
        "    targets.append(tokenized_text[i+1:i+window_size+1])\n",
        "special_tokens = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "\n",
        "def yield_tokens(data):\n",
        "    for tokens in data:\n",
        "        yield tokens\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens([tokenized_text]), specials=special_tokens, special_first=True)\n",
        "vocab.set_default_index(vocab['<unk>'])\n",
        "\n",
        "def tensor_transform(tokens):\n",
        "    token_ids = [vocab[token] for token in tokens]\n",
        "    return torch.tensor([vocab['<bos>']] + token_ids + [vocab['<eos>']], dtype=torch.long)\n",
        "\n",
        "class NextTokenDataset(Dataset):\n",
        "\n",
        "    def __init__(self, inputs, targets, transform):\n",
        "        self.inputs = inputs\n",
        "        self.targets = targets\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.transform(self.inputs[idx]), self.transform(self.targets[idx])\n",
        "\n",
        "def collate_fn(batch):\n",
        "    inputs, targets = zip(*batch)\n",
        "    return pad_sequence(inputs, padding_value=vocab['<pad>']), pad_sequence(targets, padding_value=vocab['<pad>'])\n",
        "\n",
        "dataset = NextTokenDataset(inputs, targets, tensor_transform)\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "class LSTMLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.W_f = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
        "        self.U_f = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "        self.b_f = nn.Parameter(torch.Tensor(hidden_size))\n",
        "        self.W_i = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
        "        self.U_i = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "        self.b_i = nn.Parameter(torch.Tensor(hidden_size))\n",
        "        self.W_g = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
        "        self.U_g = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "        self.b_g = nn.Parameter(torch.Tensor(hidden_size))\n",
        "        self.W_o = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
        "        self.U_o = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "        self.b_o = nn.Parameter(torch.Tensor(hidden_size))\n",
        "\n",
        "    def forward(self, input, h_prev, c_prev):\n",
        "        f = torch.sigmoid(input @ self.W_f + h_prev @ self.U_f + self.b_f)\n",
        "        k = f * c_prev\n",
        "        i = torch.sigmoid(input @ self.W_i + h_prev @ self.U_i + self.b_i)\n",
        "        g = torch.tanh(input @ self.W_g + h_prev @ self.U_g + self.b_g)\n",
        "        j = i * g\n",
        "        o = torch.sigmoid(input @ self.W_o + h_prev @ self.U_o + self.b_o)\n",
        "        c_next = k + j\n",
        "        h_next = o * torch.tanh(c_next)\n",
        "        return h_next, c_next\n",
        "\n",
        "class StackLSTMLayers(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, num_layers=1):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.layers = nn.ModuleList([LSTMLayer(input_size if i == 0 else hidden_size, hidden_size) for i in range(num_layers)])\n",
        "\n",
        "    def forward(self, input, hidden=None):\n",
        "        if hidden is None:\n",
        "            hidden = self.init_hidden(input.size(1))\n",
        "        hiddens, cells = hidden\n",
        "        outputs = []\n",
        "        for input_t in input:\n",
        "            for layer_idx, layer in enumerate(self.layers):\n",
        "                hiddens[layer_idx], cells[layer_idx] = layer(input_t, hiddens[layer_idx], cells[layer_idx])\n",
        "                if layer_idx < self.num_layers - 1:\n",
        "                    input_t = hiddens[layer_idx]\n",
        "            outputs.append(hiddens[-1])\n",
        "        outputs = torch.stack(outputs, dim=0)\n",
        "        return outputs, (hiddens, cells)\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        hiddens = [torch.zeros(batch_size, self.hidden_size, device=device) for _ in range(self.num_layers)]\n",
        "        cells = [torch.zeros(batch_size, self.hidden_size, device=device) for _ in range(self.num_layers)]\n",
        "        return hiddens, cells\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.rnn = StackLSTMLayers(emb_dim, hid_dim, n_layers)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        _, (hidden, cell) = self.rnn(embedded)\n",
        "        return hidden, cell\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.rnn = StackLSTMLayers(emb_dim, hid_dim, n_layers)\n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input, hidden, cell):\n",
        "        input = input.unsqueeze(0)\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
        "        prediction = self.fc_out(output.squeeze(0))\n",
        "        return prediction, hidden, cell\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        assert encoder.hid_dim == decoder.hid_dim, \"Hidden dimensions must be equal!\"\n",
        "        assert encoder.n_layers == decoder.n_layers, \"Encoder and decoder must have equal layers!\"\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "        batch_size = trg.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        hidden, cell = self.encoder(src)\n",
        "        input = trg[0, :]\n",
        "        for t in range(1, trg_len):\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "            outputs[t] = output\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = output.argmax(1)\n",
        "            input = trg[t] if teacher_force else top1\n",
        "        return outputs\n",
        "\n",
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def train(model, dataloader, optimizer, criterion, clip):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for src, trg in dataloader:\n",
        "        src = src.to(device)\n",
        "        trg = trg.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, trg)\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "    return epoch_loss / len(dataloader)\n",
        "\n",
        "def evaluate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for src, trg in dataloader:\n",
        "            src = src.to(device)\n",
        "            trg = trg.to(device)\n",
        "            output = model(src, trg, 0)\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "            loss = criterion(output, trg)\n",
        "            epoch_loss += loss.item()\n",
        "    return epoch_loss / len(dataloader)\n",
        "\n",
        "INPUT_DIM = len(vocab)\n",
        "OUTPUT_DIM = len(vocab)\n",
        "ENC_EMB_DIM = 128\n",
        "DEC_EMB_DIM = 128\n",
        "HID_DIM = 256\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.2\n",
        "DEC_DROPOUT = 0.2\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)\n",
        "model.apply(init_weights)\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=vocab['<pad>'])\n",
        "N_EPOCHS = 5\n",
        "CLIP = 1.0\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    train_loss = train(model, dataloader, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, dataloader, criterion)\n",
        "    end_time = time.time()\n",
        "    epoch_mins = int((end_time - start_time) // 60)\n",
        "    epoch_secs = int((end_time - start_time) % 60)\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "metadata": {
        "id": "I9jtGozrST4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_next_word(model: Seq2Seq, prompt: str) -> str:\n",
        "    model.eval()\n",
        "    tokens = tokenizer(prompt)\n",
        "    src_tensor = tensor_transform(tokens).unsqueeze(1).to(device)\n",
        "    hidden, cell = model.encoder(src_tensor)\n",
        "    input_tok = torch.tensor([vocab['<bos>']], device=device)\n",
        "    output, _, _ = model.decoder(input_tok, hidden, cell)\n",
        "    top1 = output.argmax(1)\n",
        "    token_idx = top1.item()\n",
        "    return vocab.get_itos()[token_idx]\n",
        "\n",
        "test_indices = random.sample(range(len(dataset)), 10)\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "for idx in test_indices:\n",
        "    inp_tensor, tgt_tensor = dataset[idx]\n",
        "    gt_token = vocab.get_itos()[tgt_tensor.tolist()[-2]]\n",
        "    prompt_tokens = [vocab.get_itos()[i] for i in inp_tensor.tolist() if i not in (vocab['<bos>'], vocab['<eos>'])]\n",
        "    prompt_str = \" \".join(prompt_tokens)\n",
        "    pred_token = generate_next_word(model, prompt_str)\n",
        "    total += 1\n",
        "    if pred_token == gt_token:\n",
        "        correct += 1\n",
        "    print(\"Prompt:\", prompt_str)\n",
        "    print(\"Ground Truth:\", gt_token)\n",
        "    print(\"Predicted:\", pred_token)\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "accuracy: float = correct / total\n",
        "print(\"Accuracy over 10 examples:\", accuracy)\n"
      ],
      "metadata": {
        "id": "QLIyoum4a_kj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "prompt_box = widgets.Text(\n",
        "    value='Stately, plump Buck Mulligan',\n",
        "    placeholder='Type something',\n",
        "    description='Prompt:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "generate_button = widgets.Button(description=\"Generate Text\")\n",
        "output_box = widgets.Output()\n",
        "\n",
        "def on_generate_clicked(b):\n",
        "    with output_box:\n",
        "        output_box.clear_output()\n",
        "        prompt_text = prompt_box.value\n",
        "        generated = generate_next_word(model, prompt_text)\n",
        "        print(prompt_text, generated)\n",
        "\n",
        "generate_button.on_click(on_generate_clicked)\n",
        "display(prompt_box, generate_button, output_box)"
      ],
      "metadata": {
        "id": "HvNTG4sxUNTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"You are not really that interested in what you have to say \"\n",
        "complete = \"\"\n",
        "for i in range(100):\n",
        "    complete += f\" {prompt}\"\n",
        "    prompt = generate_next_word(model, prompt)\n",
        "print(complete)"
      ],
      "metadata": {
        "id": "NFT_rnYFbKKC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}